---
title: "blogpost"
author: "Edanur & Thomas"
date: "7/30/2019"
output: 
  md_document:
    toc: true
    variant: gfm
bibliography: applied-predictive-analytics.bib
link-citations: yes
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

```{r library_helper_functions, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
seed <- 111222333
set.seed(seed)
source("helpers.r")
```

## Introduction

The paper [@banerjee2015MiracleMicrofinanceEvidence] presents the results from the randomized evaluation of a group-lending microcredit program in Hyderabad, India. Microcredit has been lent to groups of 6 to 10 women by a microfinance institution, Spandana. According to the baseline survey conducted in 2005, 104 neighborhoods with no pre-existing microfinance was selected. They were paired up and one of each pair was randomly assigned to the treatment group. Spandana then progressively began operating in the 52 treatment areas between 2006 and 2007. As an important point to highlight, the treatment was not a credit take-up but an easy access to microcredit.

### Why Index Variables

Instead of analyzing specific household behaviors such as business investment or consumption on nondurable goods, as the original paper did, we want to focus on the more general aspect of the well-being. This could be done by utilizing the “Index” variables provided by the dataset.

These index variables are the weighted average of related variables. For example, business index is the weighted average of business asset, business expenses, business profit etc. By doing so, the index variable become a holistic representation of an aspect of well-being and can capture general condition of that aspect. In the example above, business index could represent the overall circumstances of the business activities of the households.

## Data Exploration

The paper [@banerjee2015MiracleMicrofinanceEvidence] comes with 5 datasets, including data gathered in the first endline survey and second endline survey as well as data gathered in the baseline survey.

This project uses mainly the endline dataset, specifically the first endline data. The baseline dataset would be useful to calculate the changes across time. However, in our case, the index of households is different between baseline dataset and endline dataset. Hence we can not make one-to-one mapping between households in the two datasets. And since we are mainly interested in how easy accessibility to Spandana microcredits affect households well-being, only the data collected in the first endline survey will be used in this project.

```{r load_and_structure}
endline1 <- load_endline1()
str(endline1)
```

In total 6129 households completed the first endline survey. There are 56 variables in the dataset which contain the information of a household's basic properties (the household size `hhsize_adj_1`, how old is the household head `head_age_1`), their financial/loans status (whether they took loans `anyloan_1`, how many bank loan they took `bank_amt_1`), their businesses status if any (profits `bizprofit_1`, assets `bizassets_1`), their monthly expenditures on various types of good (expenditure on nondurable goods per capita `nondurable_exp_mo_pc_1`), and the calculated index variables.

## Methods

In this section we will present the structure of our analysis as well as the methods we used this project.

Traditional Response Models vs. Uplift Modeling (I read about this at the reference with *, I also write it at the motivation part as one of the reasons why we picked an uplift model)

We picked 3 models:

- Causal forest
- Causal KNN (??)
- Two Model Approach

### Structure of Analysis

This section describes the general structure of the analysis and the methods used for each task. The details of each method will be discussed in the next section.

1. Detect whether the treatment effect on the selected index variable exhibits heterogeneity  
This is vital as our "welfare-enhancing policies" is based on the assumption of targeting only the households with   relatively large treatment effect. Hence if the treatment effect is homogeneous, which means all households exhibit similar treatment effect, then the targeting policies would be inefficient.  To perform this task, Two-model Approach with Sorted Groups Average Treatment Effect (GATES), which was proposed by Chernozhukov [@chernozhukov2018GenericMachineLearning], will be used.

2. Find the variables that separate households with higher treatment effect  
If the treatment effect is heterogeneous, next thing to do is to try to separate those high treatment effect households. For this task we will use to methods, Causal Random Forest and Two-model Approach with Random Forest.  
    i) Causal Forest  
    The causal forest’s splitting rule builds trees and mimics the process that would be used if the treatment eﬀects were
    observed [@hitsch2018HeterogeneousTreatmentEffects].  
    ii) Two-Model Approach  
    There is no conventional way to get variable importance using Two-Model Approach. However, given the
    predictedconditional treatment effect we could further fit a Random Forest model to get the variable importance.

3. Find the thresholds for given variables that could make the policies more performing  
Narrowing the target could make the policy more efficient and better performing. Hence after knowing which variables make the highest impact on households’ treatment effect, our next step is then to investigate at which values of those variables a household could benefit the most from the treatment.  To accomplish this, we will use partial dependence plots to analyze those critical values.

### Two-Model Approach And Sorted Group Average Treatment Effect

Two-model approach was proposed by Chernozhukov et al. as a method for estimating average treatment effects [@chernozhukov2016DoubleDebiasedMachine],[@chernozhukov2017DoubleDebiasedNeyman]. The concept is fairly straightforward. Since machine learning has been shown to be highly effective in prediction, two-model approach exploits this feature by fitting one machine learning method on the control group and the other on the treatment group. This way we obtain one model that could be used to predict the “baseline” effect, which is defined as the outcomes if the subjects were not treated, and the other model that could be used to predict the outcomes if they were treated. We could use the two models to predict baseline effect and treatment effect for each subject. Then the conditional treatment is simply the difference between them.

Sorted group average treatment effect was proposed by Chernozhukov et al. as one of the strategies to estimate and make inferences on key features of heterogeneous treatment effects. [@chernozhukov2018GenericMachineLearning].

## Business Index

### Prepare The Dataset

```{r biz_dataset}
target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(total_biz_1 != 0) %>%
  select(everything(),
         -hhid,
         -contains("biz"),   # exclude business related variables
         -contains("index"), # exclude all index variables
         target_index)       # add back the target index variable
```

### GATES

```{r biz_tm, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
num.iters <- 10
tm_gates_biz <- tm_gates("biz_index_all_1", "treatment", endline1_biz,
                         split_ratio = 0.5,
                         cluster="areaid", num.iter=num.iters, ml_method="rf")
```

```{r biz_gates, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
alpha <- 0.05
groups <- 5
gates_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = groups))
gates_plot_data[, 1] <- c("1", "2", "3", "4", "5")
for (i in 1:5) {
  gates_plot_data[i, 2] <- median(tm_gates_biz[[1]][, i])
  gates_plot_data[i, 3] <- median(tm_gates_biz[[1]][, i+5])
  gates_plot_data[i, 4] <- median(tm_gates_biz[[1]][, i+10])
}
colnames(gates_plot_data) <- c("G", "F", "U", "L")

bp_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = 10))
bp_plot_data[,1] <- c(-Inf, Inf)
for (i in 1:3) {
  bp_plot_data[,i+1] <- median(tm_gates_biz[[2]][, i])
}
colnames(bp_plot_data) <- c("x", "ATE", "L", "U")

ggplot() + 
  theme_gray(base_size = 14) +
  geom_point(data=gates_plot_data,
             aes(y = F, x = G, colour='GATES'),
             size = 3) +
  geom_errorbar(data=gates_plot_data,
                aes(ymax = U, ymin = L ,
                    x = G, width=0.7, colour="90% CB(GATES)"),
                show.legend = TRUE) +
  geom_line(aes(x = x, y = ATE, 
                linetype = cutoff, 
                colour='ATE'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = U, 
                linetype = cutoff, 
                colour='90% CB(ATE)'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = L, 
                linetype = cutoff), 
            bp_plot_data, 
            linetype = 2,
            color = "red") +
  scale_colour_manual(values = c("red", "black", "blue", "black"),
                      breaks=c('ATE','90% CB(ATE)',"GATES",'90% CB(GATES)'),
                      guide = guide_legend(override.aes = list(
                        linetype = c("dashed", "dashed"  ,"blank", "solid"),
                        shape = c(NA,NA, 16, NA)), 
                        ncol =2,
                        byrow=TRUE)) +
  theme(plot.title = element_text(hjust = 0.5,size = 11, face = "bold"),
        axis.title=element_text(size=10), 
        legend.text=element_text(size=7), 
        legend.key = element_rect(colour = NA, fill = NA), 
        legend.key.size = unit(1, 'lines'),
        legend.title=element_blank(),
        legend.justification=c(0,1), 
        legend.position=c(0,1), 
        legend.background=element_rect(fill=alpha('blue', 0)))  +
  ylim(range(-0.3, 0.5)) +
  labs(title="GATES with Random Forest on Business Index", 
       y = "Treatment Effect", x = "Group")
```

### Variable Importance

```{r biz_tm_varimp, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
main <- tm_gates_biz[[3]]
tm_rf_biz <- randomForest(cte ~ . -treatment-areaid-baseline-G1-G2-G3-G4-G5-biz_index_all_1-prop_score-treat_group-prop_offset-weight-cte_ort-treatment_ort,
                          data = main,
                          ntree = 3000,
                          mtry = 3,
                          replace = TRUE,
                          type="regression")
```

```{r biz_crf_varimp, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
target_index <- "biz_index_all_1"

# test/train
idx.train <- caret::createDataPartition(y = endline1_biz$treatment, p = 0.70, list = FALSE) 
train <- endline1_biz[idx.train, ] # training set
test <-  endline1_biz[-idx.train, ]

# train data
Y <- train$biz_index_all_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
biz_crf <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE,
  seed = seed)
```

```{r biz_varimp, echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
biz_crf_var_imp <- var_imp_plot(biz_crf)
biz_tm_var_imp <- var_imp_plot_rf(tm_rf_biz)
cowplot::plot_grid(biz_crf_var_imp, biz_tm_var_imp)
```

## Business Index Without Expenditures Variables

### Prepare The Dataset

```{r biz_noexp_dataset}
target_index <- "biz_index_all_1"

endline1_biz_noexp <- endline1 %>%
  filter(total_biz_1 != 0) %>%
  select(everything(),
         -hhid,
         -contains("biz"),   # exclude business related variables
         -contains("exp"),   # exclude expenditures related variables
         -contains("index"), # exclude all index variables
         target_index)       # add back the target index variable
```

### GATES

```{r biz_noexp_tm, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
num.iters <- 10
tm_gates_biz_noexp <- tm_gates("biz_index_all_1", "treatment", endline1_biz_noexp,
                               split_ratio = 0.5,
                               cluster="areaid", num.iter = num.iters, ml_method = "rf")
```

```{r biz_noexp_gates, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
alpha <- 0.05
groups <- 5
gates_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = groups))
gates_plot_data[, 1] <- c("1", "2", "3", "4", "5")
for (i in 1:5) {
  gates_plot_data[i, 2] <- median(tm_gates_biz_noexp[[1]][, i])
  gates_plot_data[i, 3] <- median(tm_gates_biz_noexp[[1]][, i+5])
  gates_plot_data[i, 4] <- median(tm_gates_biz_noexp[[1]][, i+10])
}
colnames(gates_plot_data) <- c("G", "F", "U", "L")

bp_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = 10))
bp_plot_data[,1] <- c(-Inf, Inf)
for (i in 1:3) {
  bp_plot_data[,i+1] <- median(tm_gates_biz_noexp[[2]][, i])
}
colnames(bp_plot_data) <- c("x", "ATE", "L", "U")

ggplot() + 
  theme_gray(base_size = 14) +
  geom_point(data=gates_plot_data,
             aes(y = F, x = G, colour='GATES'),
             size = 3) +
  geom_errorbar(data=gates_plot_data,
                aes(ymax = U, ymin = L ,
                    x = G, width=0.7, colour="90% CB(GATES)"),
                show.legend = TRUE) +
  geom_line(aes(x = x, y = ATE, 
                linetype = cutoff, 
                colour='ATE'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = U, 
                linetype = cutoff, 
                colour='90% CB(ATE)'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = L, 
                linetype = cutoff), 
            bp_plot_data, 
            linetype = 2,
            color = "red") +
  scale_colour_manual(values = c("red", "black", "blue", "black"),
                      breaks=c('ATE','90% CB(ATE)',"GATES",'90% CB(GATES)'),
                      guide = guide_legend(override.aes = list(
                        linetype = c("dashed", "dashed"  ,"blank", "solid"),
                        shape = c(NA,NA, 16, NA)), 
                        ncol =2,
                        byrow=TRUE)) +
  theme(plot.title = element_text(hjust = 0.5,size = 11, face = "bold"),
        axis.title=element_text(size=10), 
        legend.text=element_text(size=7), 
        legend.key = element_rect(colour = NA, fill = NA), 
        legend.key.size = unit(1, 'lines'),
        legend.title=element_blank(),
        legend.justification=c(0,1), 
        legend.position=c(0,1), 
        legend.background=element_rect(fill=alpha('blue', 0)))  +
  ylim(range(-0.3, 0.5)) +
  labs(title="GATES (Business Index without Expenditures Covariates)", 
       y = "Treatment Effect", x = "Group")
```

### Variable Importance

```{r biz_noexp_tm_varimp, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
main <- tm_gates_biz_noexp[[3]]
biz_noexp_tm_rf <- randomForest(cte ~ . -treatment-areaid-baseline-G1-G2-G3-G4-G5-biz_index_all_1-prop_score-treat_group-prop_offset-weight-cte_ort-treatment_ort,
                          data = main,
                          ntree = 3000,
                          mtry = 3,
                          replace = TRUE,
                          type="regression")
```

```{r biz_noexp_crf_varimp, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
target_index <- "biz_index_all_1"

# test/train
idx.train <- caret::createDataPartition(y = endline1_biz_noexp$treatment, p = 0.70, list = FALSE) 
train <- endline1_biz_noexp[idx.train, ] # training set
test <-  endline1_biz_noexp[-idx.train, ]

# train data
Y <- train$biz_index_all_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
biz_noexp_crf <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE,
  seed = seed)
```

```{r biz_noexp_varimp, echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
biz_noexp_crf_var_imp <- var_imp_plot(biz_noexp_crf)
biz_noexp_tm_var_imp <- var_imp_plot_rf(biz_noexp_tm_rf)
cowplot::plot_grid(biz_noexp_crf_var_imp, biz_noexp_tm_var_imp)
```

### Most Efficient Value

```{r biz_noexp_crf_pred, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
biz_noexp_crf_pred <- predict(object = biz_noexp_crf,
                              newdata = model.matrix(~ ., data = test, estimate.variance = TRUE))
test$preds <- biz_noexp_crf_pred$predictions
```

```{r biz_noexp_tm_pred, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
biz_noexp_tm_rf_pred <- predict(biz_noexp_tm_rf, newdata=main)
main[, "preds"] <- biz_noexp_tm_rf_pred
```

#### Informal Loan Amount

```{r biz_noexp_trend_informal_amt, echo=FALSE, fig.height=3, fig.width=8}
biz_noexp_crf_trend_informal_amt <- trend_plot(test, "informal_amt_1", "Amount of Informal Loan", "Causal Random Forest")
biz_noexp_tm_trend_informal_amt <- trend_plot(main, "informal_amt_1", "Amount of Informal Loan", "Two-model Approach")
cowplot::plot_grid(biz_noexp_crf_trend_informal_amt, biz_noexp_tm_trend_informal_amt, ncol = 2)
```

```{r biz_noexp_pdp_informal_amt, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
biz_noexp_tm_pdp_informal_amt <- pdp_plot(biz_noexp_tm_rf, main, 
                                          "informal_amt_1", "Amount of Informal Loan", "Two-model Approach")
biz_noexp_crf_pdp_informal_amt <- pdp_plot(biz_noexp_crf, X,
                                           "informal_amt_1", "Amount of Informal Loan", "Causal Random Forest")
cowplot::plot_grid(biz_noexp_crf_pdp_informal_amt, biz_noexp_tm_pdp_informal_amt, ncol = 2)
```

#### Adjusted Household Size

```{r biz_noexp_trend_hhsize_adj, echo=FALSE, fig.height=3, fig.width=8}
biz_noexp_crf_trend_hhsize_adj <- trend_plot(test, "hhsize_adj_1", "Adjusted Household Size", "Causaul Random Forest")
biz_noexp_tm_trend_hhsize_adj <- trend_plot(main, "hhsize_adj_1", "Adjusted Household Size", "Two-model Approach")
cowplot::plot_grid(biz_noexp_crf_trend_hhsize_adj, biz_noexp_tm_trend_hhsize_adj, ncol = 2)
```

```{r biz_noexp_pdp_hhsize_adj, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
biz_noexp_tm_pdp_hhsize_adj <- pdp_plot(biz_noexp_tm_rf, main, 
                                        "hhsize_adj_1", "Adjusted Household Size", "Two-model Approach")
biz_noexp_crf_pdp_hhsize_adj <- pdp_plot(biz_noexp_crf, X,
                                         "hhsize_adj_1", "Adjusted Household Size", "Causal Random Forest")
cowplot::plot_grid(biz_noexp_crf_pdp_hhsize_adj, biz_noexp_tm_pdp_hhsize_adj, ncol = 2)
```

#### Head Age

```{r biz_noexp_trend_head_age, fig.height=3, fig.width=8}
biz_noexp_crf_trend_head_age <- trend_plot(test, "head_age_1", "Head Age", "Causaul Random Forest")
biz_noexp_tm_trend_head_age <- trend_plot(main, "head_age_1", "Head Age", "Two-model Approach")
cowplot::plot_grid(biz_noexp_crf_trend_head_age, biz_noexp_tm_trend_head_age, ncol = 2)
```

```{r biz_noexp_pdp_head_age, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
biz_noexp_tm_pdp_head_age <- pdp_plot(biz_noexp_tm_rf, main, 
                                      "head_age_1", "Head Age", "Two-model Approach")
biz_noexp_crf_pdp_head_age <- pdp_plot(biz_noexp_crf, X,
                                       "head_age_1", "Head Age", "Causal Random Forest")
cowplot::plot_grid(biz_noexp_crf_pdp_head_age, biz_noexp_tm_pdp_head_age, ncol = 2)
```

## Women Empowerment Index

### Prepare The Dataset

```{r woemp_dataset}
target_index <- "women_emp_index_1"
endline1_woemp <- endline1 %>%
  select(everything(),
         -hhid,
         -contains("index"), # exclude all index variables
         target_index)       # add back the target index variable
```

### GATES

```{r woemp_tm, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
num.iters <- 10
tm_gates_woemp <- tm_gates("women_emp_index_1", "treatment", endline1_woemp,
                           split_ratio = 0.5,
                           cluster="areaid", num.iter=num.iters, ml_method="rf")
```

```{r woemp_gates, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
alpha <- 0.05
groups <- 5
gates_plot_woemp <- data.frame(matrix(NA, ncol = 4, nrow = groups))
gates_plot_woemp[, 1] <- c("1", "2", "3", "4", "5")
for (i in 1:5) {
  gates_plot_woemp[i, 2] <- median(tm_gates_woemp[[1]][, i])
  gates_plot_woemp[i, 3] <- median(tm_gates_woemp[[1]][, i+5])
  gates_plot_woemp[i, 4] <- median(tm_gates_woemp[[1]][, i+10])
}
colnames(gates_plot_woemp) <- c("G", "F", "U", "L")

bp_plot_woemp <- data.frame(matrix(NA, ncol = 4, nrow = 10))
bp_plot_woemp[,1] <- c(-Inf, Inf)
for (i in 1:3) {
  bp_plot_woemp[,i+1] <- median(tm_gates_woemp[[2]][, i])
}
colnames(bp_plot_woemp) <- c("x", "ATE", "L", "U")

ggplot() + 
  theme_gray(base_size = 14) +
  geom_point(data=gates_plot_woemp,
             aes(y = F, x = G, colour='GATES'),
             size = 3) +
  geom_errorbar(data=gates_plot_woemp,
                aes(ymax = U, ymin = L ,
                    x = G, width=0.7, colour="90% CB(GATES)"),
                show.legend = TRUE) +
  geom_line(aes(x = x, y = ATE, 
                linetype = cutoff, 
                colour='ATE'), 
            bp_plot_woemp, 
            linetype = 2) +
  geom_line(aes(x = x, y = U, 
                linetype = cutoff, 
                colour='90% CB(ATE)'), 
            bp_plot_woemp, 
            linetype = 2) +
  geom_line(aes(x = x, y = L, 
                linetype = cutoff), 
            bp_plot_woemp, 
            linetype = 2,
            color = "red") +
  scale_colour_manual(values = c("red", "black", "blue", "black"),
                      breaks=c('ATE','90% CB(ATE)',"GATES",'90% CB(GATES)'),
                      guide = guide_legend(override.aes = list(
                        linetype = c("dashed", "dashed"  ,"blank", "solid"),
                        shape = c(NA,NA, 16, NA)), 
                        ncol =2,
                        byrow=TRUE)) +
  theme(plot.title = element_text(hjust = 0.5,size = 11, face = "bold"),
        axis.title=element_text(size=10), 
        legend.text=element_text(size=7), 
        legend.key = element_rect(colour = NA, fill = NA), 
        legend.key.size = unit(1, 'lines'),
        legend.title=element_blank(),
        legend.justification=c(0,1), 
        legend.position=c(0,1), 
        legend.background=element_rect(fill=alpha('blue', 0)))  +
  ylim(range(-0.3, 0.5)) +
  labs(title="GATES (Women Empowerment Index)", 
       y = "Treatment Effect", x = "Group by Het Score")
```

### Variable Importance

```{r woemp_tm_varimp, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
main <- tm_gates_woemp[[3]]
woemp_tm_rf <- randomForest(cte ~ . -treatment-areaid-baseline-G1-G2-G3-G4-G5-women_emp_index_1-prop_score-treat_group-prop_offset-weight-cte_ort-treatment_ort,
                          data = main,
                          ntree = 3000,
                          mtry = 3,
                          replace = TRUE,
                          type="regression")
```

```{r woemn_crf_varimp, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
target_index <- "women_emp_index_1"

# test/train
idx.train <- caret::createDataPartition(y = endline1_woemp$treatment, p = 0.70, list = FALSE) 
train <- endline1_woemp[idx.train, ] # training set
test <-  endline1_woemp[-idx.train, ]

# train data
Y <- train$women_emp_index_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
woemp_crf <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE,
  seed = seed)
```

```{r woemp_varimp, echo=FALSE, fig.height=5, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
woemp_crf_var_imp <- var_imp_plot(woemp_crf)
woemp_tm_var_imp <- var_imp_plot_rf(woemp_tm_rf)
cowplot::plot_grid(woemp_crf_var_imp, woemp_tm_var_imp)
```

###  Most Efficient Value

```{r woemp_crf_pred, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
woemp_crf_pred <- predict(object = woemp_crf,
                          newdata = model.matrix(~ ., data = test, estimate.variance = TRUE))
test$preds <- woemp_crf_pred$predictions
```

```{r woemp_tm_pred, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
woemp_tm_rf_pred <- predict(woemp_tm_rf, newdata=main)
main[, "preds"] <- woemp_tm_rf_pred
```

#### Durable Goods Expenditures

```{r woemp_trend_durables_exp, echo=FALSE, fig.height=3, fig.width=8}
woemp_crf_trend_durables_exp <- trend_plot(test, 
                                           "durables_exp_mo_pc_1", "Durable Goods Expenses (month/person)",
                                           "Causal Random Forest")
woemp_tm_trend_durables_exp <- trend_plot(main,
                                          "durables_exp_mo_pc_1", "Durable Goods Expenses (month/person)",
                                          "Two-model Approach")
cowplot::plot_grid(woemp_crf_trend_durables_exp, woemp_tm_trend_durables_exp, ncol = 2)
```

```{r woemp_pdp_durables_exp, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
woemp_tm_pdp_durables_exp <- pdp_plot(woemp_tm_rf, main, 
                                      "durables_exp_mo_pc_1", "Durable Goods Expenses (month/person)", 
                                      "Two-model Approach")
woemp_crf_pdp_durables_exp <- pdp_plot(woemp_crf, X,
                                       "durables_exp_mo_pc_1", "Durable Goods Expenses (month/person)", 
                                       "Causal Random Forest")
cowplot::plot_grid(woemp_crf_pdp_durables_exp, woemp_tm_pdp_durables_exp, ncol = 2)
```

#### Adjusted Household Size

```{r woemp_trend_hhsize_adj, echo=FALSE, fig.height=3, fig.width=8}
woemp_crf_trend_hhsize_adj <- trend_plot(test, 
                                         "hhsize_adj_1", "Adjusted Household Size", "Causal Random Forest")
woemp_tm_trend_hhsize_adj <- trend_plot(main,
                                        "hhsize_adj_1", "Adjusted Household Size", "Two-model Approach")
cowplot::plot_grid(woemp_crf_trend_hhsize_adj, woemp_tm_trend_hhsize_adj, ncol = 2)
```

```{r woemp_pdp_hhsize_adj, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
woemp_tm_pdp_hhsize_adj <- pdp_plot(woemp_tm_rf, main, 
                                    "hhsize_adj_1", "Adjusted Household Size", "Two-model Approach")
woemp_crf_pdp_hhsize_adj <- pdp_plot(woemp_crf, X,
                                     "hhsize_adj_1", "Adjusted Household Size", "Causal Random Forest")
cowplot::plot_grid(woemp_crf_pdp_hhsize_adj, woemp_tm_pdp_hhsize_adj, ncol = 2)
```

#### Head Age

```{r woemp_head_age, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
woemp_crf_trend_head_age <- trend_plot(test, "head_age_1", "Head Age", "Causal Random Forest")
woemp_tm_trend_head_age <- trend_plot(main, "head_age_1", "Head Age", "Two-model Approach")
cowplot::plot_grid(woemp_crf_trend_head_age, woemp_tm_trend_head_age, ncol = 2)
```

```{r woemp_pdp_hhsize_adj, fig.height=3, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
woemp_tm_pdp_head_age <- pdp_plot(woemp_tm_rf, main, "head_age_1", "Head Agd", "Two-model Approach")
woemp_crf_pdp_head_age <- pdp_plot(woemp_crf, X, "head_age_1", "Head Age", "Causal Random Forest")
cowplot::plot_grid(woemp_crf_pdp_head_age, woemp_tm_pdp_head_age, ncol = 2)
```

## Models Comparison

Measuring and comparing the performance of our two methods is not straightforward as calculating MSE (mean square error) or determining the accuracy. Since in real life causal inference problems, we do not have the true treatment effect. Then the above mentioned metrics can not apply under this circumstance as they need to compare the predicted value with the true value. 
Usually for uplift models, the metric used to compare the performances of different methods is Qini score (add references). (maybe add some advantages of Qini score and why people usually use it).
However, considering the target variables we selected in this project are continuous instead of categorical, Qini score is not suitable in our case. There are ways to circumvent this issue. For example we could convert the numeric values into binaries based on some predefined thresholds that indicate whether or not a household “really” benefit from the treatment. (Add the reasons why we didn’t do this.)
The other comparing method is to use the transformed outcomes as “true” value and calculate the distance of predicted value and the transformed outcome. This way the conventional error measurement, such as mean absolute error (MAE) and mean square error (MSE), could be implemented to assess the model performance. For this project we decided to use transformed outcome approach with mean square error as the error metric when comparing the performances of the two methods.

## References
