# Setup The Environment

## Load The Packages

```{r}
library(readstata13)
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(lfe)
library(grf)
```

# Data Preparation And Exploration

## Load The Datasets

```{r}
endlines <- read.dta13("data/2013-0533_data_endlines1and2.dta",
                       generate.factors = T)
```

## The Structure And Summary

```{r}
str(endlines)
```

```{r}
colnames(endlines)
```

## Convert Factors to Binary Variable

```{r}
for (covar in colnames(endlines)) {
  if (is.factor(endlines[, covar]) == TRUE) {
    endlines[, covar] <- as.numeric(endlines[, covar]) - 1
  }
}
```

## Split Endline1 And Endline2

```{r}
endline1 <- endlines %>%
  filter(sample1 == 1) %>%
  select(colnames(endlines)[1:16], contains("_1"),
         -c("hhid","w", "w1", "w2", "sample1", "sample2"))
```

```{r}
str(endline1)
```


## Missing Values

```{r}
endline1$girl515_workhrs_pc_1 <- NULL
endline1$boy515_workhrs_pc_1 <- NULL
endline1$girl1620_school_1 <- NULL
endline1$boy1620_school_1 <- NULL
endline1$girl515_school_1 <- NULL
endline1$boy515_school_1 <- NULL
endline1$female_biz_pct_1 <- NULL
endline1$hours_child1620_week_1 <- NULL
endline1$hours_girl1620_week_1 <- NULL
endline1$hours_boy1620_week_1 <- NULL
endline1$biz_stop_1 <- NULL
endline1$biz_index_new_1 <- NULL
endline1$biz_index_old_1 <- NULL
```

### Fill with Median
```{r}
for (covar in colnames(endline1)) {
  if (is.numeric(endline1[, covar]) == TRUE) {
    endline1[is.na(endline1[, covar]), covar] <- median(endline1[, covar], 
                                                        na.rm = TRUE)
  }
}
sapply(endline1, function(x) sum(is.na(x)))
```

## Merge the Date

```{r}
endline1$visitdate <- as.Date(with(endline1, paste(visityear_1, visitmonth_1, visitday_1,sep="-")), "%Y-%m-%d")
str(endline1$visitdate)
summary(endline1$visitdate)
```

```{r}
endline1$visitday_1 <- NULL
endline1$visitmonth_1 <- NULL
endline1$visityear_1 <- NULL
endline1$visitdate <- NULL
endline1$w1 <- NULL
endline1$w2 <- NULL
```

# Design Of The Study

We want to study the effect of "availibility of microcredit" on different aspects of the households in Hyderabad, India: 

- Business
- ...

However, the fact that in the original study, they didn't collect the baseline data in a very rigorous way and they were not confident enough that the baseline data is representative of the slum of whole.  Hence the baseline data was only as a basis for stratification, the descriptive analysis, and to collect **area-level characteristics** that are used as control variables.

Because of the flaw of our datasets, we lose the ability to directly link baseline data with endlines data, hence could not perform the analysis on household-level. To mitigate this issue, we use the "index variables", which were calculated by the authors and were included in our dataset, as our target variables. And we assumed that those variables already include the information we need to analyze the causal effect.

### How They Calculate The Results in The Original Paper

For each "target" variable, they run an weighted OLS:

$y_{ia} = \alpha + \beta * Treatment_a + X'\gamma + \epsilon_{ia}$

```{r}
spandana_amt <- felm(spandana_amt_1 ~ 1 + treatment + area_pop_base + 
                     area_business_total_base + area_exp_pc_mean_base + 
                     area_literate_head_base + area_literate_base + 
                     area_debt_total_base, 
                     data = endline1,
                     weights = endline1$w1)

summary(spandana_amt)
```

```{r}
endline1 %>%
  filter(treatment == "Control") %>%
  summarize(mean = mean(spandana_amt_1, na.rm = TRUE))
```

# Business Index

## Treatment & Target Variable

- Treatment Variable:  `treatment`
- Target Variable: `biz_index_all_1`

We want to find out whether there are heterogeneous effects of  "availibility of Spandana microcredit loan" on business in the area.

```{r}
endline1 %>%
  filter(is.na(treatment) == FALSE) %>% # exclude the observations with NA
  group_by(treatment) %>%
  summarize("Num. of Obs." = n(),
            "Ave. Biz. Index" = mean(biz_index_all_1, na.rm = TRUE))
```

## Dataset

### TO DO any_biz_1?
### TO DO exclude indexes?

```{r}
target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(is.na(target_index) != TRUE) %>%
  select(everything(),
         -contains("area"),
         -contains("index"),                              # prevent confounding
         areaid,
         target_index)                                    # add target index
str(endline1_biz)
```

## Two-Models Approach With Sorted Group Average Treatment Effects (GATES)

### By Random Forest

```{r}
tm_gates <- function(target, treatment, data, 
                     split_ratio=0.5, cluster=0, num.iter=100, 
                     ml_method="rf") {
  
  # a list to store the regression results
  results <- list()
  
  # TODO implement user specified num.groups
  num.groups <- 5
  
  if (cluster != 0) {
    strati_target <- cluster
  } else {
    strati_target <- treatment
  }
  
  for (i in 1:num.iter) {
    # set seed for reproduction
    set.seed(i)
  
    # seperate auxi and main sample  
    auxi_index <- createDataPartition(data[,strati_target],
                                      p = split_ratio, 
                                      list = FALSE)
    auxi <- data[auxi_index, ]
    main <- data[-auxi_index,]
  
    # seperate treatment & control in the auxiliary sample
    auxi_treat_index <- which(auxi[,treatment] == 1)
    auxi_treat <- auxi[auxi_treat_index, ]
    auxi_contr <- auxi[-auxi_treat_index,]

    # use the specified machine learning method to predict the conditional treatment effect
    if (ml_method == "rf") {
      # fit a random forest on auxi_treat and auxi_contr
      auxi_formula <- as.formula(paste(target, " ~ .", "-", treatment))
      auxi_yi0 <- randomForest(auxi_formula,
                               data = auxi_contr,
                               ntree = 3000,
                               mtry = 3,
                               replace = TRUE,
                               type = "regression")
      auxi_yi1 <- randomForest(auxi_formula,
                               data = auxi_treat,
                               ntree = 3000,
                               mtry = 3,
                               replace = TRUE,
                               type = "regression")
      # predict the baseline effect and conditional treatment effect on main sample
      main_yi0 <- predict(auxi_yi0, newdata = main)
      main_yi1 <- predict(auxi_yi1, newdata = main)
      main$baseline <- main_yi0
      main$cte <- (main_yi1 - main_yi0)
    } else if (ml_method == "crf") {
      # fit a causal random forest on auxi sample
      auxi_X <- auxi %>%
        select(everything(), -target, -treatment)
      auxi_Y <- auxi[, target]
      auxi_W <- auxi[, treatment]
      auxi_crf <- causal_forest(X = auxi_X,
                                Y = auxi_Y,
                                W = auxi_W,
                                honesty = TRUE,
                                mtry = 3,
                                num.trees = 3000)
      # predict the conditional treatment effect on main sample
      auxi_crf_pred <- predict(auxi_crf, newdata = main)
      main$cte <- auxi_crf_pred$predictions
    }
    
    # TWO-MODELS APPROACH
    # Fit regression on conditional treatment effect
    tm_exclude_col <- c(target, treatment, cluster,
                        "baseline", "cte")
    data_col <- names(main)
    tm_formula <- as.formula(
      paste(
        "cte", "~",
        paste(data_col[!data_col %in% tm_exclude_col], collapse = " + ")))
  
    tm_model <- felm(tm_formula,
                     data = main,
                     weights = main$weight)
    
    results[[i]] <- tm_model
    
    # SORTED GROUP AVERAGE TREATMENT EFFECT
    # calculate propensity score (treated/all)    
    # TODO implement option to use non-randomized treatment assignment
    prop_score <- nrow(data[data$treatment == 1, ])/nrow(data)      
    main$prop_score <- prop_score
    
    # divide observations based on their predicted conditional treatment effect  
    breaks <- quantile(main$cte, seq(0,1, 1/num.groups), include.lowest = TRUE)
    breaks[1] <- breaks[1] - 0.001
    breaks[6] <- breaks[6] + 0.001
    main$treat_group <- cut(main$cte, breaks = breaks)
  
    # calculate the propensity score offset for each observation in main sample
    main$prop_offset <- main$treatment - main$prop_score
  
    # construct matrix from each observation's group factor
    SGX <- model.matrix(~-1+main$treat_group)
    # construct D-p(X)*1(G_k) and weight for each observation
    DSG <- data.frame(main$prop_offset*SGX)
    colnames(DSG) <- c("G1", "G2", "G3", "G4", "G5")
    main[,c("G1", "G2", "G3", "G4", "G5", "weight")] <- cbind(
      DSG$G1, DSG$G2, DSG$G3, DSG$G4, DSG$G5,
      1/prop_score*(1-prop_score))
  
    # fit weighted ols
    if (ml_method == "rf") {
      gates_formula <- as.formula(paste(target,
                                        "~",
                                        "-1+baseline+cte+G1+G2+G3+G4+G5",
                                        "|0|0|",
                                        cluster))
    } else if (ml_method == "crf") {
      gates_formula <- as.formula(paste(target,
                                        "~",
                                        "-1+cte+G1+G2+G3+G4+G5",
                                        "|0|0|",
                                        cluster))
    }

    gates_model <- felm(gates_formula,
                        data = main,
                        weights = main$weight)

    results[[num.iter+i]] <- gates_model
  }
  return(results)
}
```

#### With Minimal Dataset

```{r}
endline1_biz_mini <- endline1_biz %>%
  select(everything(),
         -contains("biz"),
         -ends_with("mo_1"),
         biz_index_all_1)
```

```{r}
tm_gates_biz_mini <- tm_gates("biz_index_all_1", "treatment", endline1_biz_mini,
                              split_ratio = 0.6,
                              cluster="areaid", num.iter=1, ml_method="rf")
```

```{r}
summary(tm_gates_biz_mini[[1]])
```

```{r}
summary(tm_gates_biz_mini[[2]])
```

```{r}
tm_gates_biz_mini_crf <- tm_gates("biz_index_all_1", "treatment", endline1_biz_mini,
                                  split_ratio = 0.6,
                                  cluster="areaid", num.iter=1, ml_method="crf")
```

```{r}
summary(tm_gates_biz_mini_crf[[1]])
```

```{r}
summary(tm_gates_biz_mini_crf[[2]])
```

# CAUSAL FOREST

## Var_imp_plot function
```{r}
var_imp_plot <- function(forest, decay.exponent = 2L, max.depth = 4L) {
  
  # Calculate variable importance of all features
  # (from print.R)
  split.freq <- split_frequencies(forest, max.depth)
  split.freq <- split.freq / pmax(1L, rowSums(split.freq))
  weight <- seq_len(nrow(split.freq)) ^ -decay.exponent
  var.importance <- t(split.freq) %*% weight / sum(weight)
  
  # Format data frame
  p <- ncol(forest$X.orig)
  
  var.names <- colnames(forest$X.orig)[seq_len(p)]
  if (is.null(var.names)) {
    var.names <- paste0('x', seq_len(p))
  }
  df <- tibble(Variable = var.names,
               Importance = as.numeric(var.importance)) %>%
    arrange(Importance) %>% 
    mutate(Variable = factor(Variable, levels = unique(Variable)))
  
  # Plot results
  p <- ggplot(df, aes(Variable, Importance)) + 
    geom_bar(stat = 'identity') + 
    coord_flip() + 
    ggtitle('Variable Importance') + 
    theme_bw() + 
    theme(plot.title = element_text(hjust = 0.5))
  print(p)
}
```

## Business Index
```{r}
target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(any_biz_1 == 1) %>%
  select(everything(),
         -any_biz_1)  
str(endline1_biz)

y <- endline1_biz$biz_index_all_1
X <- endline1_biz %>% 
  select(
    everything(), -treatment, -hhid,
-contains("index"), -contains("biz"), -contains("area"), 
-hhsize_1, -adults_1, children_1 
)
clusters <- endline1_biz$areaid
W <- endline1_biz$treatment

set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

## Credit Index
```{r}
target_index <- "credit_index_1"

y <- endline1$credit_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("amt"), -contains("mfi"), 
-spandana_1, -anyloan_1, -anybank_1, -anyinformal_1, -everlate_1,
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

set.seed(123)
forest_without_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

## Home Durable Index
```{r}
target_index <- "home_durable_index_1"

y <- endline1$home_durable_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("exp"), bizexpense_1, 
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

str(X)
set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

## Consumption Index
```{r}
target_index <- "consumption_index_1"

y <- endline1$consumption_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("exp"), bizexpense_1, 
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

str(X)
set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

```{r}
index <- endline1 %>%
select(contains("index"))
str(index)
