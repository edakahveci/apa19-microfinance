# Setup The Environment

## Load The Packages

```{r}
library(readstata13)
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(lfe)
library(grf)
```

# Data Preparation And Exploration

## Load The Datasets

```{r}
endlines <- read.dta13("data/2013-0533_data_endlines1and2.dta",
                       convert.factors = FALSE,
                       generate.factors = TRUE)
```

## The Structure And Summary

```{r}
str(endlines)
```

## Split Endline1 And Endline2

```{r}
endline1 <- endlines %>%
  filter(sample1 == 1) %>%
  select(colnames(endlines)[1:16], contains("_1"))
```

```{r}
str(endline1)
```

## Exclude Irrelevant Covariates

There are some variables in the dataset that are only relevant when the data were collected, such as the information of when the inspectors visit the households and if the households were included in the endline surveys.

```{r}
endline1 <- endline1 %>%
  select(-c(w, w1, w2, sample1, sample2, visitday_1, visitmonth_1, visityear_1))
```

## Exclude Redundant Covariates

Since we are going to use `areaid` to do cluster analysis, including the area-level variables doesn't make much sense.

```{r}
endline1 <- endline1 %>%
  select(-starts_with("area_"))
```

The dataset include both total expense and per-capita version for each expense category per month (or annual). To prevent issues with overspecified (irrelevant variables), we exclude the total expenses and only leave the per-capita variables.

```{r}
endline1 <- endline1 %>%
  select(-ends_with("mo_1"),
         -ends_with("annual_1"))
```

## Deleting the Outliers

```{r}
for (i in colnames(endline1)) {
endline1 <- endline1[
  (endline1[,i] < mean(endline1[,i], na.rm=TRUE)+3*sd(endline1[,i], na.rm=TRUE) | endline1[,i] < mean(endline1[,i], na.rm=TRUE)-3*sd(endline1[,i], na.rm=TRUE)),]
}

```

```{r}
endline1_outlier <- endline1[
  (endline1$biz_index_all_1 < mean(endline1$biz_index_all_1, na.rm=TRUE)+3*sd(endline1$biz_index_all_1, na.rm=TRUE) | endline1$biz_index_all_1 < mean(endline1$biz_index_all_1, na.rm=TRUE)-3*sd(endline1$biz_index_all_1, na.rm=TRUE)),]
```

## Missing Values

We will first delete the covariates that contains a huge amount of missing values. Then we will look into the remaining covariates and fill them with custom methods.

First we need to find out which variable contains unreasonable amount of missing value.

```{r}
# set the threshold of na ratio
na_delete_threshold <- 0.2

na_ratio_endline1 <- data.frame()
for (i in 1:ncol(endline1)) {
  n_na <- nrow(endline1[is.na(endline1[,i]),])
  na_ratio <- n_na / nrow(endline1)
  na_ratio_endline1[i, 1] <- colnames(endline1)[[i]]
  na_ratio_endline1[i, 2] <- na_ratio
}

colnames(na_ratio_endline1) <- c("covariate", "na_ratio")
na_ratio_endline1 %>% filter(na_ratio > na_delete_threshold)
```

We will delete those variables as the information might not be helpful.

```{r}
# select the variables that has a large amount of missing value
na_delete_col <- (na_ratio_endline1 %>% filter(na_ratio > na_delete_threshold))[,1]
# delete those variables
for (col in na_delete_col) {
  endline1[,col] <- NULL
}
```

### Business-related Variables

`old_biz` and `any_old_biz` contain similar information, the former indicates how many old businesses a household own prior to the first endline and the latter is a binary variable that indicates whether a household has at least an old business. Here we combine the two variables and assume those households that didn't answer the question was either not a busniess owner at all or not understood the question. Either ways, we could safely consider them as having 0 old busineses.

```{r}
endline1 <- endline1 %>%
  mutate(old_biz = ifelse(any_old_biz == 0 | is.na(any_old_biz) == TRUE,
                          0,
                          old_biz))
# Delete any_old_biz as the information is combined with old_biz
endline1$any_old_biz <- NULL
```

The same reasoning could be apply to `total_biz_1` and `any_biz_1`.

```{r}
endline1 <- endline1 %>%
  mutate(total_biz_1 = ifelse(any_biz_1 == 0 | is.na(any_biz_1) == TRUE,
                              0,
                              total_biz_1))
# Delete any_biz_1 as the information is combined with total_biz_1
endline1$any_biz_1 <- NULL
```

### Fill with Median

```{r}
for (covar in colnames(endline1)) {
  if (is.numeric(endline1[, covar]) == TRUE) {
    endline1[is.na(endline1[, covar]), covar] <- median(endline1[, covar], 
                                                        na.rm = TRUE)
  }
}
sapply(endline1, function(x) sum(is.na(x)))
```

### Check The Result

Check how many complete cases we have.

```{r}
length(endline1$hhid[complete.cases(endline1)])
```


## Merge the Date

```{r}
endline1$visitdate <- as.Date(with(endline1, paste(visityear_1, visitmonth_1, visitday_1,sep="-")), "%Y-%m-%d")
str(endline1$visitdate)
summary(endline1$visitdate)
```

```{r}
endline1$visitday_1 <- NULL
endline1$visitmonth_1 <- NULL
endline1$visityear_1 <- NULL
endline1$visitdate <- NULL
endline1$w1 <- NULL
endline1$w2 <- NULL
```

# Design Of The Study

We want to study the effect of "availibility of microcredit" on different aspects of the households in Hyderabad, India: 

- Business
- ...

However, the fact that in the original study, they didn't collect the baseline data in a very rigorous way and they were not confident enough that the baseline data is representative of the slum of whole.  Hence the baseline data was only as a basis for stratification, the descriptive analysis, and to collect **area-level characteristics** that are used as control variables.

Because of the flaw of our datasets, we lose the ability to directly link baseline data with endlines data, hence could not perform the analysis on household-level. To mitigate this issue, we use the "index variables", which were calculated by the authors and were included in our dataset, as our target variables. And we assumed that those variables already include the information we need to analyze the causal effect.

### How They Calculate The Results in The Original Paper

For each "target" variable, they run an weighted OLS:

$y_{ia} = \alpha + \beta * Treatment_a + X'\gamma + \epsilon_{ia}$

```{r}
spandana_amt <- felm(spandana_amt_1 ~ 1 + treatment + area_pop_base + 
                     area_business_total_base + area_exp_pc_mean_base + 
                     area_literate_head_base + area_literate_base + 
                     area_debt_total_base, 
                     data = endline1,
                     weights = endline1$w1)

summary(spandana_amt)
```

```{r}
endline1 %>%
  filter(treatment == "Control") %>%
  summarize(mean = mean(spandana_amt_1, na.rm = TRUE))
```

# Business Index

## Treatment & Target Variable

- Treatment Variable:  `treatment`
- Target Variable: `biz_index_all_1`

We want to find out whether there are heterogeneous effects of  "availibility of Spandana microcredit loan" on business in the area.

```{r}
endline1 %>%
  filter(is.na(treatment) == FALSE) %>% # exclude the observations with NA
  group_by(treatment) %>%
  summarize("Num. of Obs." = n(),
            "Ave. Biz. Index" = mean(biz_index_all_1, na.rm = TRUE))
```

## Dataset

### TO DO any_biz_1?
### TO DO exclude indexes?

```{r}
target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(any_biz_1 == 1) %>%
  select(everything(),
         -any_biz_1,
#         -contains("index"),                              # prevent confounding
         target_index)                                    # add target index
str(endline1_biz)
```

## Two-Models Approach With Sorted Group Average Treatment Effects (GATES)

## F-Tests
```{r}
auxi_ind <- createDataPartition(y = endline1$treatment, p = 0.7, list = FALSE)
auxi <- endline1[auxi_ind, ]
main <- endline1[-auxi_ind,]

auxi_treat_ind <- which(auxi[,"treatment"] == 1)
auxi_treat <- auxi[auxi_treat_ind, ]
auxi_contr <- auxi[-auxi_treat_ind,]

var.test(auxi_treat$spouse_literate_1, auxi_contr$spouse_literate_1, alternative = "two.sided")
var.test(auxi_treat$spouse_works_wage_1, auxi_contr$spouse_works_wage_1, alternative = "two.sided")
var.test(auxi_treat$hhsize_1, auxi_contr$hhsize_1, alternative = "two.sided")
var.test(auxi_treat$women1845_1, auxi_contr$women1845_1, alternative = "two.sided")
var.test(auxi_treat$anychild1318_1, auxi_contr$anychild1318_1, alternative = "two.sided")
var.test(auxi_treat$old_biz, auxi_contr$old_biz, alternative = "two.sided")
var.test(auxi_treat$ownland_hyderabad_1, auxi_contr$ownland_hyderabad_1, alternative = "two.sided")
var.test(auxi_treat$ownland_village_1, auxi_contr$ownland_village_1, alternative = "two.sided")

for (covar in colnames(auxi_treat)) {
  F_test <- var.test(auxi_treat[,covar], auxi_contr[,covar], alternative = "two.sided")
  signif_value <- 0.05
  print(ifelse(F_test$p.value < 0.05, covar, 0))
  }

treated <- endline1 %>%
  filter(treatment == 1)

control <- endline1 %>%
  filter(treatment == 0)
 
var.test(treated$spouse_literate_1, control$spouse_literate_1, alternative = "two.sided")
var.test(treated$spouse_works_wage_1, control$spouse_works_wage_1, alternative = "two.sided")
var.test(treated$hhsize_1, control$hhsize_1, alternative = "two.sided")
var.test(treated$women1845_1, control$women1845_1, alternative = "two.sided")
var.test(treated$anychild1318_1, control$anychild1318_1, alternative = "two.sided")
var.test(treated$old_biz, control$old_biz, alternative = "two.sided")
var.test(treated$ownland_hyderabad_1, control$ownland_hyderabad_1, alternative = "two.sided")
var.test(treated$ownland_village_1, control$ownland_village_1, alternative = "two.sided")

for (covar in colnames(treated)) {
  F_test <- var.test(treated[,covar], control[,covar], alternative = "two.sided")
  signif_value <- 0.05
  print(ifelse(F_test$p.value < 0.05, covar, 0))
  }

# The p-value of F-test is greater than the significance level 0.05. In conclusion, there is no significant difference between the two variances.

```


### By Random Forest

```{r}
rf_tm <- function(target, treatment, data, cluster=NULL, num.iter=100) {
  
  results <- list()
  
  # TODO implement user specified num.groups
  num.groups <- 5
  
  # if cluster is not specified, use 0 as the placeholder
  if (is.null(cluster) == TRUE) {
    cluster <- 0
  }

  for (i in 1:num.iter) {
    # set seed for reproduction
    seed <- i
    set.seed(seed)
  
    # seperate auxi and main sample  
    auxi_ind <- createDataPartition(data[,target], p = 0.7, list = FALSE)
    auxi <- data[auxi_ind, ]
    main <- data[-auxi_ind,]
  
    # seperate treatment & control in the auxiliary sample
    auxi_treat_ind <- which(auxi[,treatment] == 1)
    auxi_treat <- auxi[auxi_treat_ind, ]
    auxi_contr <- auxi[-auxi_treat_ind,]

    # fit a model to for auxi_treat and auxi_contr
    auxi_formula <- as.formula(paste(target, " ~ ", "."))
    auxi_yi0 <- randomForest(biz_index_all_1 ~ .,
                             data = auxi_contr,
                             ntree = 3000,
                             mtry = 3,
                             replace = TRUE,
                             type = "regression")
    auxi_yi1 <- randomForest(auxi_formula,
                             data = auxi_treat,
                             ntree = 3000,
                             mtry = 3,
                             replace = TRUE,
                             type = "regression")
    
    # TODO implement option to use non-randomized treatment assignment
    if (TRUE) {
      # calculate propensity score (treated/all)
      prop_score <- nrow(data[data$treatment == 1, ])/nrow(data)      
    } else {
      # fit a model to predict whether a observation was treated or not
      auxi_d <- randomForest(treatment ~ . -biz_index_all_1 -hhid -w1,
                             data = auxi,
                             ntree = 1000,
                             mtry = 3,
                             replace = TRUE,
                             type = "regression")
      prop_score <- predict(auxi_d, newdata = main)
    }
    
    # assign each observation's propensity score
    main$prop_score <- prop_score

    # calculate the baseline effect and conditional treatment effect of main sample      
    main_yi0 <- predict(auxi_yi0, newdata = main)
    main_yi1 <- predict(auxi_yi1, newdata = main)
    main$baseline <- main_yi0
    main$condi_treat <- (main_yi1 - main_yi0)
  
    # Fit regression on conditional treatment effect
    tm_exclude_col <- c("hhid", "areaid", "treatment", "baseline", "condi_treat","prop_score", target)
    data_col <- names(main)
    tm_formula <- as.formula(
      paste(
        "condi_treat", "~",
        paste(data_col[!data_col %in% tm_exclude_col], collapse = " + ")))
  
    tm_model <- felm(tm_formula,
                     data = main,
                     weights = main$weight)
    
    results[[1]] <- tm_model
    
    # divide observations based on their predicted conditional treatment effect  
    breaks <- quantile(main$condi_treat, seq(0,1, 1/num.groups), include.lowest = TRUE)
    breaks[1] <- breaks[1] - 0.001
    breaks[6] <- breaks[6] + 0.001
    main$treat_group <- cut(main$condi_treat, breaks = breaks)
  
    # calculate the propensity score offset for each observation in main sample
    main$prop_offset <- main$treatment - main$prop_score
  
    # construct matrix from each observation's group factor
    SGX <- model.matrix(~-1+main$treat_group)
    # construct D-p(X)*1(G_k) and weight for each observation
    DSG <- data.frame(main$prop_offset*SGX)
    colnames(DSG) <- c("G1", "G2", "G3", "G4", "G5")
    main[,c("G1", "G2", "G3", "G4", "G5", "weight")] <- cbind(
      DSG$G1, DSG$G2, DSG$G3, DSG$G4, DSG$G5,
      1/prop_score*(1-prop_score))
  
    # fit weighted ols
    exclude_col <- c(target_index, "hhid", "areaid", "treatment", 
                     "prop_score", "treat_group", "prop_offset", "weight")
    data_col <- names(main)
    gates_formula <- as.formula(paste(target,
                                      "~",
                                      "-1+baseline+condi_treat+G1+G2+G3+G4+G5",
                                      "|0|0|",
                                      cluster))
    gates_model <- felm(gates_formula,
                        data = main,
                        weights = main$weight)
    
    results[[2]] <- gates_model
  }
  return(results)
}
```

### With All The Covariates

```{r}
tm_gates_biz <- rf_tm("biz_index_all_1", "treatment", 
                      endline1_biz, cluster = "areaid", num.iter = 1)
```

### Without Business-related Covariates

```{r}
endline1_biz_nobiz <- endline1_biz %>%
  select(everything(), -contains("biz"), biz_index_all_1)
```

```{r}
tm_gates_biz_nobiz <- rf_tm("biz_index_all_1", "treatment", 
                            endline1_biz_nobiz, cluster = "areaid", num.iter = 1)
```

### Without Business-related Covariates and without Other Indexes

#### Prepare The Dataset
```{r}
endline1_biz_wo <- endline1_biz %>%
  select(everything(), -contains("biz"), -contains("index"), biz_index_all_1)
```

#### Run The Model
```{r}
tm_gates_biz_wo <- rf_gates("biz_index_all_1", "treatment", 
                         endline1_biz_wo, cluster = "areaid", num.iter = 1)
```

#### Results: Two-Models Approach
```{r}
summary(tm_gates_biz_wo[[1]])
```

#### Results: GATES
```{r}
summary(tm_gates_biz_wo[[2]])
```

# CAUSAL FOREST

## Var_imp_plot function
```{r}
var_imp_plot <- function(forest, decay.exponent = 2L, max.depth = 4L) {
  
  # Calculate variable importance of all features
  # (from print.R)
  split.freq <- split_frequencies(forest, max.depth)
  split.freq <- split.freq / pmax(1L, rowSums(split.freq))
  weight <- seq_len(nrow(split.freq)) ^ -decay.exponent
  var.importance <- t(split.freq) %*% weight / sum(weight)
  
  # Format data frame
  p <- ncol(forest$X.orig)
  
  var.names <- colnames(forest$X.orig)[seq_len(p)]
  if (is.null(var.names)) {
    var.names <- paste0('x', seq_len(p))
  }
  df <- tibble(Variable = var.names,
               Importance = as.numeric(var.importance)) %>%
    arrange(Importance) %>% 
    mutate(Variable = factor(Variable, levels = unique(Variable)))
  
  # Plot results
  p <- ggplot(df, aes(Variable, Importance)) + 
    geom_bar(stat = 'identity') + 
    coord_flip() + 
    ggtitle('Variable Importance') + 
    theme_bw() + 
    theme(plot.title = element_text(hjust = 0.5))
  print(p)
}
```

## Business Index
```{r}
target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(any_biz_1 == 1) %>%
  select(everything(),
         -any_biz_1)  
str(endline1_biz)

# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_biz$treatment, p = 0.75, list = FALSE) 
train <- endline1_biz[idx.train, ] # training set
test <-  endline1_biz[-idx.train, ]

# train data
y <- train$biz_index_all_1
X <- train %>% 
  select(
    everything(), -treatment, -hhid, 
-contains("index"), -contains("biz"), -contains("area"), -contains("mo_1"),
-hhsize_adj_1 ,-hhsize_1, -adults_1, -children_1, areaid, -festival_exp_annual_1
)
clusters <- train$areaid
W <- train$treatment

# model
set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)

# test data
test_y <- test$biz_index_all_1
test_X <- test %>% 
  select(
    everything(), -treatment, -hhid, 
-contains("index"), -contains("biz"), -contains("area"), -contains("mo_1"),
-hhsize_adj_1, -hhsize_1, -adults_1, -children_1, areaid, -festival_exp_annual_1
)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest_cluster, 
  newdata = model.matrix(~ ., data = test_X, 
  estimate.variance = TRUE
))
summary(train$biz_index_all_1)
test$preds <- preds$predictions

forest_cluster %>% 
  variable_importance() %>% 
  as.data.frame() %>% 
  mutate(variable = colnames(forest_cluster$X.orig)) %>% 
  arrange(desc(V1))

```




```{r}
p1 <- ggplot(test, aes(x = hours_headspouse_outside_1, y = preds)) +
  geom_point() +
  geom_smooth(method = "loess", span = 1) +
  theme_light()

p2 <- ggplot(test, aes(x = nondurable_exp_mo_pc_1, y = preds)) +
  geom_point() +
  geom_smooth(method = "loess", span = 1) +
  theme_light()

p3 <- ggplot(test, aes(x = head_age_1, y = preds)) +
  geom_point() +
  geom_smooth(method = "loess", span = 1) +
  theme_light()

p4 <- ggplot(test, aes(x = temptation_exp_mo_pc_1, y = preds)) +
  geom_point() +
  geom_smooth(method = "loess", span = 1) +
  theme_light()

install.packages("cowplot")
library(cowplot)
cowplot::plot_grid(p1, p2, p3, p4)
```




## Credit Index
```{r}
target_index <- "credit_index_1"

y <- endline1$credit_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("amt"), -contains("mfi"), 
-spandana_1, -anyloan_1, -anybank_1, -anyinformal_1, -everlate_1,
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

## Home Durable Index
```{r}
target_index <- "home_durable_index_1"

y <- endline1$home_durable_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("exp"), bizexpense_1, 
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

str(X)
set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

## Consumption Index
```{r}
target_index <- "consumption_index_1"

y <- endline1$consumption_index_1
X <- endline1 %>% 
  select(
    everything(), -treatment, -hhid, -areaid,
-contains("index"), -contains("area"), -contains("exp"), bizexpense_1, 
-hhsize_1, -adults_1, -children_1 
)
clusters <- endline1$areaid
W <- endline1$treatment

str(X)
set.seed(123)
forest_cluster <- causal_forest(
  model.matrix(~., data = X),
  y,
  W,
  clusters = clusters,
  mtry = 1, num.trees = 1000)
forest_cluster

var_imp_plot(forest_cluster)
```

```{r}
index <- endline1 %>%
select(contains("asset"))
str(index)
```
# check other variables than areaid for the clusters
