---
output:
  pdf_document: default
  html_document: default
---
# Setup The Environment

## Load The Required Packages

```{r}
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(lfe)
library(grf)
library(cowplot)
source("helpers.r")
```

# Business Index

```{r}
endline1 <- load_endline1()
str(endline1)
```

## Prepare The Dataset

```{r}
endline1 <- load_endline1()

target_index <- "biz_index_all_1"

endline1_biz <- endline1 %>%
  filter(total_biz_1 != 0) %>%
  select(everything(),
         -hhid,
         -starts_with("biz"),
         -hours_week_outside_1,
         -contains("index"), # prevent confounding
         target_index)       # add target index
str(endline1_biz)
```

## Treatment & Target Variable

- Treatment Variable:  `treatment`
- Target Variable: `biz_index_all_1`

We want to find out whether there are heterogeneous effects of  "availibility of Spandana microcredit loan" on business in the area.

```{r}
endline1_biz %>%
  group_by(treatment) %>%
  summarize("Num. of Obs." = n(),
            "Ave. Biz. Index" = mean(biz_index_all_1, na.rm = TRUE))
```

## Two-Models Approach With Sorted Group Average Treatment Effects (GATES)

### Rescale The Dataset

We rescale (standardize) the numeric variables before running the
regression in order to get a clear view on how to interpret the
results.

```{r}
preScale <- preProcess(endline1_biz[,3:(ncol(endline1_biz)-1)],
                       method = c("scale", "center"))
endline1_biz_scale <- predict(preScale, newdata = endline1_biz)
```

```{r}
biz_med <- median(endline1_biz$biz_index_all_1)
endline1_biz_bin <- endline1_biz %>%
  mutate(biz_index_all_1 =  ifelse(endline1_biz$biz_index_all_1 > biz_med,
                                   1,
                                   0))
```


### Results (using Random Forest)

```{r}
source("helpers.r")
num.iters <- 10
tm_gates_biz <- tm_gates("biz_index_all_1", "treatment", endline1_biz,
                         split_ratio = 0.5,
                         cluster="areaid", num.iter=num.iters, ml_method="rf")
```

```{r}
tm_gates_biz_bin <- tm_gates("biz_index_all_1", "treatment", endline1_biz_bin,
                         split_ratio = 0.5,
                         cluster="areaid", num.iter=num.iters, ml_method="rf")
```

```{r}
library(pdp)
auxi_contr <- tm_gates_biz[[15]]
auxi_treat <- tm_gates_biz[[16]]
```

### PDP For Durables Expenditure

```{r}
pdp_durable_contr <- tm_gates_biz[[13]] %>%
  partial(pred.var = "durables_exp_mo_pc_1",
          chull = TRUE, progress = "text")
pdp_durable_treat <- tm_gates_biz[[14]] %>%
  partial(pred.var = "durables_exp_mo_pc_1",
          chull = TRUE, progress = "text")

pdp_durable_contr[, "yhat_treat"] <- pdp_durable_treat$yhat
pdp_durable_contr[, "cte"] <- pdp_durable_contr$yhat_treat- pdp_durable_contr$yhat

ggplot() +
  geom_line(data = pdp_durable_contr, 
            aes(x=durables_exp_mo_pc_1, y=yhat), color="red") + 
  geom_line(data = pdp_durable_treat,
            aes(x=durables_exp_mo_pc_1, y=yhat), color="blue")

pdp_durable <- ggplot() +
  geom_line(data = pdp_durable_contr, aes(x=durables_exp_mo_pc_1, y=cte))
```

### PDP For Adjusted Household Size

```{r}
pdp_hhsize_contr <- tm_gates_biz[[13]] %>%
  partial(pred.var = "hhsize_adj_1",
          chull = TRUE, progress = "text")
pdp_hhsize_treat <- tm_gates_biz[[14]] %>%
  partial(pred.var = "hhsize_adj_1",
          chull = TRUE, progress = "text")

pdp_hhsize_contr[, "yhat_treat"] <- pdp_hhsize_treat$yhat
pdp_hhsize_contr[, "cte"] <- pdp_hhsize_contr$yhat_treat- pdp_hhsize_contr$yhat


ggplot() +
  geom_line(data = pdp_hhsize_contr, 
            aes(x=hhsize_adj_1, y=yhat), color="red") + 
  geom_line(data = pdp_hhsize_treat,
            aes(x=hhsize_adj_1, y=yhat), color="blue")

pdp_hhsize <- ggplot() +
  geom_line(data = pdp_hhsize_contr, aes(x=hhsize_adj_1, y=cte))
```

### PDP For Nondurable Expenditure

```{r}
pdp_nondurable_contr <- tm_gates_biz[[13]] %>%
  partial(pred.var = "nondurable_exp_mo_pc_1",
          chull = TRUE, progress = "text")
pdp_nondurable_treat <- tm_gates_biz[[14]] %>%
  partial(pred.var = "nondurable_exp_mo_pc_1",
          chull = TRUE, progress = "text")

pdp_nondurable_contr[, "yhat_treat"] <- pdp_nondurable_treat$yhat
pdp_nondurable_contr[, "cte"] <- pdp_nondurable_contr$yhat_treat- pdp_nondurable_contr$yhat

ggplot() +
  geom_line(data = pdp_nondurable_contr, 
            aes(x=nondurable_exp_mo_pc_1, y=yhat), color="red") + 
  geom_line(data = pdp_nondurable_treat,
            aes(x=nondurable_exp_mo_pc_1, y=yhat), color="blue")

pdp_nondurable <- ggplot() +
  geom_line(data = pdp_nondurable_contr, aes(x=nondurable_exp_mo_pc_1, y=cte))
```

### PDP For Health Expenditure

```{r}
pdp_health_contr <- tm_gates_biz[[13]] %>%
  partial(pred.var = "health_exp_mo_pc_1",
          chull = TRUE, progress = "text")
pdp_health_treat <- tm_gates_biz[[14]] %>%
  partial(pred.var = "health_exp_mo_pc_1",
          chull = TRUE, progress = "text")

pdp_health_contr[, "yhat_treat"] <- pdp_health_treat$yhat
pdp_health_contr[, "cte"] <- pdp_health_contr$yhat_treat- pdp_health_contr$yhat

ggplot() +
  geom_line(data = pdp_health_contr, 
            aes(x=health_exp_mo_pc_1, y=yhat), color="red") + 
  geom_line(data = pdp_health_treat,
            aes(x=health_exp_mo_pc_1, y=yhat), color="blue")

pdp_health <- ggplot() +
  geom_line(data = pdp_health_contr, aes(x=health_exp_mo_pc_1, y=cte))
```

### PDP

```{r}
cowplot::plot_grid(pdp_hhsize, pdp_nondurable, pdp_health, pdp_durable)
```


```{r}
library(tools4uplift)
library(uplift)
```

```{r}
gates_perf <- uplift::performance(1 - tm_gates_biz[[9]],
                                  1 - tm_gates_biz[[8]],
                                  tm_gates_biz[[7]]$biz_index_all_1,
                                  tm_gates_biz[[7]]$treatment)
uplift::qini(gates_perf, direction = 1, plotit = TRUE)
```

```{r}
apply(tm_gates_biz[[2]], 2, median)
apply(tm_gates_biz[[3]], 2, median)
apply(tm_gates_biz[[4]], 2, median)
apply(tm_gates_biz[[5]], 2, median)
```

```{r}
ave_dur_exp_plot_data <- cbind(data.frame(apply(tm_gates_biz[[2]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_dur_exp_plot_data) <- c("ave_dur_exp", "group")
ggplot(ave_dur_exp_plot_data, aes(x=group, y=ave_dur_exp, label=ave_dur_exp)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_dur_exp)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Durable Expenditure (mo/pc)") +
  ylim(0, 100)
```

```{r}
ave_loan_amt_plot_data <- cbind(data.frame(apply(tm_gates_biz[[3]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_loan_amt_plot_data) <- c("ave_loan_amt_exp", "group")
ggplot(ave_loan_amt_plot_data, aes(x=group, y=ave_loan_amt_exp, label=ave_loan_amt_exp)) + 
  geom_col() +
  geom_text(aes(label=round(ave_loan_amt_exp)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Loan Amount") +
  ylim(0, 150000)
```

```{r}
ave_nondur_exp_plot_data <- cbind(data.frame(apply(tm_gates_biz[[4]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_nondur_exp_plot_data) <- c("ave_nondur_exp", "group")
ggplot(ave_nondur_exp_plot_data, aes(x=group, y=ave_nondur_exp, label=ave_nondur_exp)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_nondur_exp)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Nondurable Expenditure (mo/pc)") +
  ylim(0, 1800)
```

```{r}
ave_food_exp_plot_data <- cbind(data.frame(apply(tm_gates_biz[[5]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_food_exp_plot_data) <- c("ave_food_exp", "group")
ggplot(ave_food_exp_plot_data, aes(x=group, y=ave_food_exp, label=ave_food_exp)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_food_exp)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Food Expenditure (mo/pc)") +
  ylim(0, 700)
```

```{r}
ave_health_exp_plot_data <- cbind(data.frame(apply(tm_gates_biz[[6]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_health_exp_plot_data) <- c("ave_health_exp", "group")
ggplot(ave_health_exp_plot_data, aes(x=group, y=ave_health_exp, label=ave_health_exp)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_health_exp)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Health Expenditure (mo/pc)") +
  ylim(0, 100)
```

```{r}
ave_hhsize_adj_plot_data <- cbind(data.frame(apply(tm_gates_biz[[7]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_hhsize_adj_plot_data) <- c("ave_hhsize_adj", "group")
ggplot(ave_hhsize_adj_plot_data, aes(x=group, y=ave_hhsize_adj, label=ave_hhsize_adj)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_hhsize_adj, 5)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Household Size (adjusted)") +
  ylim(0, 6)
```

```{r}
ave_head_age_plot_data <- cbind(data.frame(apply(tm_gates_biz[[8]], 2, median)), c("G1", "G2", "G3", "G4", "G5"))
colnames(ave_head_age_plot_data) <- c("ave_head_age", "group")
ggplot(ave_head_age_plot_data, aes(x=group, y=ave_head_age, label=ave_head_age)) + 
  geom_col() + 
  geom_text(aes(label=round(ave_head_age, 5)), hjust=0, vjust=-2) +
  labs(x = "Group", y = "Average Head Age") +
  ylim(0, 80)
```


### GATES

```{r}
alpha <- 0.05
groups <- 5
gates_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = groups))
gates_plot_data[, 1] <- c("1", "2", "3", "4", "5")
for (i in 1:5) {
  gates_plot_data[i, 2] <- median(tm_gates_biz[[1]][, i])
  gates_plot_data[i, 3] <- median(tm_gates_biz[[1]][, i+5])
  gates_plot_data[i, 4] <- median(tm_gates_biz[[1]][, i+10])
}
colnames(gates_plot_data) <- c("G", "F", "U", "L")
```

```{r}
bp_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = 10))
bp_plot_data[,1] <- c(-Inf, Inf)
for (i in 1:3) {
  bp_plot_data[,i+1] <- median(tm_gates_biz[[9]][, i])
}
colnames(bp_plot_data) <- c("x", "ATE", "L", "U")
```

```{r}
ggplot() + 
  theme_gray(base_size = 14) +
  geom_point(data=gates_plot_data,
             aes(y = F, x = G, colour='GATES'),
             size = 3) +
  geom_errorbar(data=gates_plot_data,
                aes(ymax = U, ymin = L ,
                    x = G, width=0.7, colour="90% CB(GATES)"),
                show.legend = TRUE) +
  geom_line(aes(x = x, y = ATE, 
                linetype = cutoff, 
                colour='ATE'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = U, 
                linetype = cutoff, 
                colour='90% CB(ATE)'), 
            bp_plot_data, 
            linetype = 2) +
  geom_line(aes(x = x, y = L, 
                linetype = cutoff), 
            bp_plot_data, 
            linetype = 2,
            color = "red") +
  scale_colour_manual(values = c("red", "black", "blue", "black"),
                      breaks=c('ATE','90% CB(ATE)',"GATES",'90% CB(GATES)'),
                      guide = guide_legend(override.aes = list(
                        linetype = c("dashed", "dashed"  ,"blank", "solid"),
                        shape = c(NA,NA, 16, NA)), 
                        ncol =2,
                        byrow=TRUE)) +
  theme(plot.title = element_text(hjust = 0.5,size = 11, face = "bold"),
        axis.title=element_text(size=10), 
        legend.text=element_text(size=7), 
        legend.key = element_rect(colour = NA, fill = NA), 
        legend.key.size = unit(1, 'lines'),
        legend.title=element_blank(),
        legend.justification=c(0,1), 
        legend.position=c(0,1), 
        legend.background=element_rect(fill=alpha('blue', 0)))  +
  ylim(range(-0.3, 0.5)) +
  labs(title="GATES with Random Forest on Business Index", 
       y = "Treatment Effect", x = "Group by Het Score")
```

# CAUSAL FOREST

## Business Index

```{r}
# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_biz$treatment, p = 0.70, list = FALSE) 
train <- endline1_biz[idx.train, ] # training set
test <-  endline1_biz[-idx.train, ]

# train data
Y <- train$biz_index_all_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
forest <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 5000,
  honesty = TRUE,
  seed = 234)
```

```{r}
var_imp_plot(forest)
```

```{r}
# test data
test_Y <- test$biz_index_all_1
test_X <- test %>% 
  select(-treatment, -target_index, -areaid)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest,
  newdata = model.matrix(~ ., data = test_X, estimate.variance = TRUE))
test$preds <- preds$predictions
trend_plots(forest, test)
```

```{r}
# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_biz_bin$treatment, p = 0.75, list = FALSE) 
train <- endline1_biz_bin[idx.train, ] # training set
test <-  endline1_biz_bin[-idx.train, ]

# train data
Y <- train$biz_index_all_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
forest <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE)

var_imp_plot(forest)

# test data
test_Y <- test$biz_index_all_1
test_X <- test %>% 
  select(-treatment, -target_index, -areaid)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest,
  newdata = model.matrix(~ ., data = test_X, estimate.variance = TRUE))
test$preds <- preds$predictions
trend_plots(forest, test)
```

```{r}
tm_gates_biz_bin[[7]]$cte <- 1 - tm_gates_biz_bin[[7]]$cte
```


```{r}
tm_qini_table <- QiniTable(tm_gates_biz_bin[[7]], "treatment", "biz_index_all_1", "cte")
crf_qini_table <- QiniTable(test, "treatment", "biz_index_all_1", "preds")
qini_plot_data <- data.frame(matrix(NA, ncol = 4, nrow = 11))
colnames(qini_plot_data) <- c("tm_X","tm_Y", "crf_X", "crf_Y")
qini_plot_data$tm_X <- c(0, tm_qini_table[, 3])/tm_qini_table[nrow(tm_qini_table), 3]*100
qini_plot_data$tm_Y <- c(0, tm_qini_table[, 7])
qini_plot_data$crf_X <- c(0, crf_qini_table[, 3])/crf_qini_table[nrow(crf_qini_table), 3]*100
qini_plot_data$crf_Y <- c(0, crf_qini_table[, 7])
```
```{r}
ggplot(qini_plot_data) + 
  geom_line(aes(x=tm_X, y=tm_Y, color = "red")) +
  geom_line(aes(x=crf_X, y=crf_Y, color = "darkblue")) +
  scale_color_discrete(name = "Methods", labels = c("Two-model", "Causal RF")) +
  labs(x="Proportion of Population Targeted (%)",
       y="Incremental Uplift (%)") +
  ylim(-10, 10)
```


```{r}
test <- cbind(test, preds)

table
QiniCurve(table)
```

```{r}
target_index <- "biz_index_all_1"

endline1_biz <- endline1[1:15]
biz_index_all_1 <- endline1$biz_index_all_1
endline1_biz <- cbind(endline1_biz, biz_index_all_1)


# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_biz$treatment, p = 0.75, list = FALSE) 
train <- endline1_biz[idx.train, ] # training set
test <-  endline1_biz[-idx.train, ]

# train data
Y <- train$biz_index_all_1
X <- train %>% 
  select(-treatment, -target_index, -areaid, -hhid)
X.clusters <- train$areaid
W <- train$treatment

# model
forest <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE)

var_imp_plot(forest)

# test data
test_Y <- test$biz_index_all_1
test_X <- test %>% 
  select(-treatment, -target_index, -areaid)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest,
  newdata = model.matrix(~ ., data = test_X, estimate.variance = TRUE))
test$preds <- preds$predictions
trend_plots(forest, test)
```

```{r}
QiniCurve(QiniTable(test, "treatment", "biz_index_all_1", "preds"))
```

### Re-run The Model With Only Important Variables

```{r}
Y.forest = regression_forest(X, Y, clusters = X.clusters)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X, W, clusters = X.clusters)
W.hat = predict(W.forest)$predictions

cf.raw = causal_forest(X, Y, W,
                       Y.hat = Y.hat, W.hat = W.hat,
                       clusters = X.clusters)

varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))

cf = causal_forest(X[,selected.idx], Y, W,
                   Y.hat = Y.hat, W.hat = W.hat,
                   clusters = X.clusters,
                   samples_per_cluster = 10,
                   tune.parameters = TRUE)

tau.hat = predict(cf)$predictions
```

### Confidence Interval for Average Treatment Effects

```{r}
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect) 
ate.low = average_treatment_effect(cf, subset = !high_effect) 

paste("95% CI for difference in ATE:",
round(ate.high[1] - ate.low[1], 3), "+/-",
round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
```

### Best Linear Predictor

```{r}
test_calibration(cf)
```
Heterogeneity with 0.1 significance.

### The Effects of `hours_week_biz_1` and `total_exp_mo_pc_1`

```{r}
area.mat = model.matrix(~ -1 + areaid, data = train)
area.size = colSums(area.mat)

dr.score = tau.hat + W / cf$W.hat * (Y - cf$Y.hat - (1 - cf$W.hat) * tau.hat) -
  (1 - W) / (1 - cf$W.hat) * (Y - cf$Y.hat + cf$W.hat * tau.hat)

area.score = area.mat * dr.score / area.size
```


```{r}
area.hours_biz = area.mat * X$hours_week_biz_1/ area.size
high_hours_biz = area.hours_biz > median(area.hours_biz) 
t.test(area.score[high_hours_biz], area.score[!high_hours_biz])
```


```{r}
area.total_exp = area.mat * X$total_exp_mo_pc_1 / area.size
high_total_exp = area.total_exp > median(area.total_exp) 
t.test(area.score[high_total_exp], area.score[!high_total_exp])
```

```{r}
area.food_exp = area.mat * X$food_exp_mo_pc_1 / area.size
high.food_exp = area.food_exp > median(area.food_exp) 
t.test(area.score[high.food_exp], area.score[!high.food_exp]) 
```
There is heterogeneity along `hours_week_biz_1` and `total_exp_mo_pc_1` with 0.05 significance.



## Credit Index
```{r}
target_index <- "credit_index_1"

endline1_credit <- endline1 %>%
  select(everything(),
         -hhid,
         -spandana_1,
         -othermfi_1,
         -anybank_1,
         -anyinformal_1,
         -anyloan_1,
         -contains("amt"),
         -contains("index"), # prevent confounding
         target_index)       # add target index
str(endline1_credit)

endline1_biz$biz_index_all_1 <- ifelse(endline1_biz$biz_index_all_1<0, 0, 1)

# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_credit$treatment, p = 0.75, list = FALSE) 
train <- endline1_credit[idx.train, ] # training set
test <-  endline1_credit[-idx.train, ]

# train data
Y <- train$credit_index_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
forest <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE)

var_imp_plot(forest)

# test data
test_Y <- test$credit_index_1
test_X <- test %>% 
  select(-treatment, -target_index, -areaid)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest,
  newdata = model.matrix(~ ., data = test_X, estimate.variance = TRUE))
test$preds <- preds$predictions
trend_plots(forest, test)
```

```{r}
test <- cbind(test, preds)
table <- QiniTable(test, "treatment", "credit_index_all_1", "predictions")
table
QiniCurve(table)
```

```{r}
Y.forest = regression_forest(X, Y, clusters = X.clusters)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X, W, clusters = X.clusters)
W.hat = predict(W.forest)$predictions

cf.raw = causal_forest(X, Y, W,
                       Y.hat = Y.hat, W.hat = W.hat,
                       clusters = X.clusters)

varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))

cf = causal_forest(X[,selected.idx], Y, W,
                   Y.hat = Y.hat, W.hat = W.hat,
                   clusters = X.clusters,
                   samples_per_cluster = 10,
                   tune.parameters = TRUE)

tau.hat = predict(cf)$predictions
```

### Confidence Interval for Average Treatment Effects

```{r}
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect) 
ate.low = average_treatment_effect(cf, subset = !high_effect) 

paste("95% CI for difference in ATE:",
round(ate.high[1] - ate.low[1], 3), "+/-",
round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
```

### Best Linear Predictor

```{r}
test_calibration(cf)
```
There is heterogeneity.

### The Effects of `total_exp_mo_pc_1` and `food_exp_mo_pc_1` and `nondurable_exp_mo_pc_1`

```{r}
area.mat = model.matrix(~ -1 + areaid, data = train)
area.size = colSums(area.mat)

dr.score = tau.hat + W / cf$W.hat * (Y - cf$Y.hat - (1 - cf$W.hat) * tau.hat) -
  (1 - W) / (1 - cf$W.hat) * (Y - cf$Y.hat + cf$W.hat * tau.hat)

area.score = area.mat * dr.score / area.size
```

```{r}
area.total_exp = area.mat * X$total_exp_mo_pc_1 / area.size
high_total_exp = area.total_exp > median(area.total_exp) 
t.test(area.score[high_total_exp], area.score[!high_total_exp])
```

The t-test shows no significant of different treatment effects between high food expenditure and 

```{r}
area.food_exp = area.mat * X$food_exp_mo_pc_1 / area.size
high.food_exp = area.food_exp > median(area.food_exp) 
t.test(area.score[high.food_exp], area.score[!high.food_exp]) 
```
```{r}
area.nondurable_exp = area.mat * X$nondurable_exp_mo_pc_1 / area.size
high.nondurable_exp = area.nondurable_exp > median(area.nondurable_exp) 
t.test(area.score[high.nondurable_exp], area.score[!high.nondurable_exp]) 
```
There is heterogeneity along `total_exp_mo_pc_1` and `food_exp_mo_pc_1` and `nondurable_exp_mo_pc_1`.


## Consumption Index
```{r}
target_index <- "consumption_index_1"

endline1_consumption <- endline1 %>%
  select(everything(),
         -hhid,
         -contains("exp"),
         bizexpense_1,
         -contains("index"), # prevent confounding
         target_index)       # add target index
str(endline1_consumption)


# test/train
set.seed(123)
idx.train <- caret::createDataPartition(y = endline1_consumption$treatment, p = 0.75, list = FALSE) 
train <- endline1_consumption[idx.train, ] # training set
test <-  endline1_consumption[-idx.train, ]

# train data
Y <- train$consumption_index_1
X <- train %>% 
  select(-treatment, -target_index, -areaid)
X.clusters <- train$areaid
W <- train$treatment

# model
forest <- causal_forest(
  model.matrix(~., data = X),
  Y,
  W,
  clusters = X.clusters,
  mtry = 3, 
  num.trees = 3000,
  honesty = TRUE)

var_imp_plot(forest)

# test data
test_Y <- test$consumption_index_1
test_X <- test %>% 
  select(-treatment, -target_index, -areaid)
test_clusters <- test$areaid
test_W <- test$treatment

# prediction
preds <- predict(
  object = forest,
  newdata = model.matrix(~ ., data = test_X, estimate.variance = TRUE))
test$preds <- preds$predictions
trend_plots(forest, test)
```




```{r}
Y.forest = regression_forest(X, Y, clusters = X.clusters)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X, W, clusters = X.clusters)
W.hat = predict(W.forest)$predictions

cf.raw = causal_forest(X, Y, W,
                       Y.hat = Y.hat, W.hat = W.hat,
                       clusters = X.clusters)

varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))

cf = causal_forest(X[,selected.idx], Y, W,
                   Y.hat = Y.hat, W.hat = W.hat,
                   clusters = X.clusters,
                   samples_per_cluster = 10,
                   tune.parameters = TRUE)

tau.hat = predict(cf)$predictions
```

### Confidence Interval for Average Treatment Effects

```{r}
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect) 
ate.low = average_treatment_effect(cf, subset = !high_effect) 

paste("95% CI for difference in ATE:",
round(ate.high[1] - ate.low[1], 3), "+/-",
round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
```

### Best Linear Predictor

```{r}
test_calibration(cf)
```
No heterogeneity. 

### The Effects of `anyloan_amt_1` and `hhsize_adj_1`

```{r}
area.mat = model.matrix(~ -1 + areaid, data = train)
area.size = colSums(area.mat)

dr.score = tau.hat + W / cf$W.hat * (Y - cf$Y.hat - (1 - cf$W.hat) * tau.hat) -
  (1 - W) / (1 - cf$W.hat) * (Y - cf$Y.hat + cf$W.hat * tau.hat)

area.score = area.mat * dr.score / area.size
```

```{r}
area.anyloan_amt = area.mat * X$anyloan_amt_1 / area.size
high_anyloan_amt = area.anyloan_amt > median(area.anyloan_amt) 
t.test(area.score[high_anyloan_amt], area.score[!high_anyloan_amt])
```

```{r}
area.hhsize_adj = area.mat * X$hhsize_adj_1 / area.size
high.hhsize_adj = area.hhsize_adj > median(area.hhsize_adj) 
t.test(area.score[high.hhsize_adj], area.score[!high.hhsize_adj]) 
```
No heterogeneity along `anyloan_amt_1` and `hhsize_adj_1`. 
